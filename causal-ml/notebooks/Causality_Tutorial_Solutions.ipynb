{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3In88vKrq4WB"
      },
      "source": [
        "# Causality Tutorial Exercises â€“ Python\n",
        "\n",
        "Contributors: Rune Christiansen, Jonas Peters, Niklas Pfister, Sorawit Saengkyongam, Sebastian Weichwald, Julius von KÃ¼gelgen.\n",
        "\n",
        "The MIT License applies; copyright is with the authors.\n",
        "\n",
        "Some exercises are adapted from \"Elements of Causal Inference: Foundations and Learning Algorithms\" by J. Peters, D. Janzing and B. SchÃ¶lkopf.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnsIE8yWlVIQ"
      },
      "source": [
        "# Exercise 1 â€“ Structural Causal Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSNemB3GrBIE"
      },
      "source": [
        "\n",
        "Let's first draw a sample from an SCM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Cy58Ut1liKd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# set seed\n",
        "np.random.seed(1)\n",
        "\n",
        "rnorm = lambda n: np.random.normal(size=n)\n",
        "\n",
        "n = 200\n",
        "C = rnorm(n)\n",
        "A = .8 * rnorm(n)\n",
        "K = A + .1 * rnorm(n)\n",
        "X = C - 2 * A + .2 * rnorm(n)\n",
        "F = 3 * X + .8 * rnorm(n)\n",
        "D = -2 * X + .5 * rnorm(n)\n",
        "G = D + .5 * rnorm(n)\n",
        "Y = 2 * K - D + .2 * rnorm(n)\n",
        "H = .5 * Y + .1 * rnorm(n)\n",
        "\n",
        "data = np.c_[C, A, K, X, F, D, G, Y, H]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PMvvEeIoKFN"
      },
      "source": [
        "__a)__\n",
        "\n",
        "What are the parents and children of $X$ in the above SCM?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![DAG](https://raw.githubusercontent.com/sweichwald/causality-tutorial-exercises/main/data/Exercise-ANM.png)\n",
        "\n",
        "**Answer:**\n",
        "- $\\mathbf{PA}_X=\\{C,A\\}$\n",
        "- $\\mathbf{CH}_X=\\{F,D\\}$"
      ],
      "metadata": {
        "id": "dLmquYZ1LKHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Take a pair of variables and think about whether you expect this pair to be dependent\n",
        "(at this stage, you can only guess, later you will have tools to know). Check empirically."
      ],
      "metadata": {
        "id": "shRv1aV0LLqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Let's check for the pairs $(C,A)$ and $(K,X)$:"
      ],
      "metadata": {
        "id": "7JIozParUdvk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtbA6c2Ron5f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "from scipy import stats\n",
        "\n",
        "# Check correlation between C and A\n",
        "\n",
        "plt.scatter(C, A)\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('A')\n",
        "plt.show()\n",
        "\n",
        "stats.pearsonr(C, A)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check correlation between K and X\n",
        "\n",
        "plt.scatter(K, X)\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('X')\n",
        "plt.show()\n",
        "\n",
        "stats.pearsonr(K, X)"
      ],
      "metadata": {
        "id": "Ns-qSaXvWnbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__b)__\n",
        "\n",
        "Generate a sample of size 300 from the interventional distribution $P_{\\mathrm{do}(X=\\mathcal{N}(2, 1))}$\n",
        "and store the data matrix as `data_int`."
      ],
      "metadata": {
        "id": "bL084MzHLBgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer to b):**\n",
        "\n",
        "To simulate the intervention, we modify the structural equation for $X$ and sample from the modified SCM."
      ],
      "metadata": {
        "id": "R0FQ1_H_W0tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C_int = rnorm(n)\n",
        "A_int = .8 * rnorm(n)\n",
        "K_int = A_int + .1 * rnorm(n)\n",
        "X_int = 2 + rnorm(n)  # this is the only change needed to model do(X=N(2,1))\n",
        "F_int = 3 * X_int + .8 * rnorm(n)\n",
        "D_int = -2 * X_int + .5 * rnorm(n)\n",
        "G_int = D_int + .5 * rnorm(n)\n",
        "Y_int = 2 * K_int - D_int + .2 * rnorm(n)\n",
        "H_int = .5 * Y_int + .1 * rnorm(n)\n",
        "\n",
        "data_int = np.c_[C_int, A_int, K_int, X_int, F_int, D_int, G_int, Y_int, H_int]"
      ],
      "metadata": {
        "id": "reu0HoxKV1cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3wOg_4vozpz"
      },
      "source": [
        "__c)__\n",
        "\n",
        "Do you expect the marginal distribution of $Y$ to be different in both samples?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "In general, yes, because $Y$ is a descendant of the intervened node $X$.\n"
      ],
      "metadata": {
        "id": "QTxTAJPPacLT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH9Tt444o-RH"
      },
      "source": [
        "__d)__\n",
        "\n",
        "Do you expect the joint distribution of $(A, Y)$ to be different in both samples?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** In general, yes: whereas the marginal of $A$ will stay the same, the conditional of $Y$ given $A$ will change since the intervention target $X$ lies on a path from $A$ to $Y$."
      ],
      "metadata": {
        "id": "yzwJ02m7abtF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZmh_AizpGp-"
      },
      "source": [
        "__e)__\n",
        "\n",
        "Check your answers to c) and d) empirically."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(Y, density=True, alpha=0.5, label=\"observational\")\n",
        "plt.hist(Y_int, density=True, alpha=0.5, label=\"interventional\")\n",
        "plt.xlabel(\"Y\")\n",
        "plt.ylabel(\"density\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HK79EHLxaZpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2PMSXqKpLpH"
      },
      "outputs": [],
      "source": [
        "plt.scatter(A, Y, alpha=0.5, label=\"observational\")\n",
        "plt.scatter(A_int, Y_int, alpha=0.5, label=\"interventional\")\n",
        "plt.xlabel(\"A\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Idk_ElwrEht"
      },
      "source": [
        "# Exercise 2 â€“ Adjusting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il0b9fnVq-bz"
      },
      "source": [
        "\n",
        "![DAG](https://raw.githubusercontent.com/sweichwald/causality-tutorial-exercises/main/data/Exercise-ANM.png)\n",
        "\n",
        "Suppose we are given a fixed DAG (like the one above).\n",
        "\n",
        "a) What are valid adjustment sets (VAS) used for?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** To compute a correct (unbiased) estimate of causal effects."
      ],
      "metadata": {
        "id": "1lH0-_CQMA_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "b) Assume we want to find a VAS for the causal effect from $X$ to $Y$.\n",
        "What are general recipies (plural ðŸ˜‰) for constructing VASs (no proof)?\n",
        "Which sets are VAS in the DAG above?\n"
      ],
      "metadata": {
        "id": "qMIT0ezQMC2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** (i) Parent adjustment via $\\mathbf{PA}_X=\\{C,A\\}$. (ii) Backdoor adjustment, i.e., any set that blocks the backdoor path $X \\leftarrow A \\to K \\to Y$, i.e., $\\{A\\}, \\{A,K\\}, \\{K\\}$; (iii) In general, any set containing at least one of $A$ or $K$, and not containing $D, G, H$."
      ],
      "metadata": {
        "id": "-QgqBN0oMFJZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) The following code samples from an SCM. Perform linear regressions using different VAS and compare the regression coefficient against the causal effect from $X$ to $Y$."
      ],
      "metadata": {
        "id": "o-wZmzaAMGu0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3y5ckYKJHiJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# set seed\n",
        "np.random.seed(1)\n",
        "\n",
        "rnorm = lambda n: np.random.normal(size=n)\n",
        "\n",
        "n = 200\n",
        "C = rnorm(n)\n",
        "A = .8 * rnorm(n)\n",
        "K = A + .1 * rnorm(n)\n",
        "X = C - 2 * A + .2 * rnorm(n)\n",
        "F = 3 * X + .8 * rnorm(n)\n",
        "D = -2 * X + .5 * rnorm(n)\n",
        "G = D + .5 * rnorm(n)\n",
        "Y = 2 * K - D + .2 * rnorm(n)\n",
        "H = .5 * Y + .1 * rnorm(n)\n",
        "\n",
        "data = np.c_[C, A, K, X, F, D, G, Y, H]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "df = pd.DataFrame(data, columns=['C', 'A', 'K', 'X', 'F', 'D', 'G', 'Y', 'H'])\n",
        "\n",
        "# print(ols('Y ~ X', df).fit().params)\n",
        "print(ols('Y ~ X + C + A + K', df).fit().params)\n",
        "# print(ols('Y ~ X + K', df).fit().params)\n",
        "# print(ols('Y ~ X + A + K', df).fit().params)\n",
        "# print(ols('Y ~ X + F + K', df).fit().params)\n",
        "print(ols('Y ~ X + C + A + K + F', df).fit().params)\n",
        "print(ols('Y ~ X + A + K + F + G + H', df).fit().params)"
      ],
      "metadata": {
        "id": "wfwnXf84gaYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** All VAS yield a regression coefficient of approximately 2 which is the causal effect of $X$ on $Y$, obtained by multiplying the path coefficients along $X\\to D \\to Y$."
      ],
      "metadata": {
        "id": "heCeMf7aitAQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqFFtwP5JQVw"
      },
      "source": [
        "d) Why could it be interesting to have several options for choosing a VAS?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- We have options to choose which variables to collect for estimating the causal effect\n",
        "- If all variables are collected. We can use different adjustment sets to validate our assumptions, e.g., the validity of underlying graph or model misspecification.\n",
        "- Even though all VASs should give the same result asymptoticallly, they may differ in terms of their finite-sample behaviour."
      ],
      "metadata": {
        "id": "mPLaIRcUUiA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "e) If you indeed have access to several VASs, what would you do?\n",
        "\n"
      ],
      "metadata": {
        "id": "_UxFM3YtUjcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Compare statistical efficiency, i.e., pick the estimator with the lowest variance.\n",
        "- Choose the set of variables we are confident about the underlying graph and the data collection process."
      ],
      "metadata": {
        "id": "BkiXti2YUl_L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ7RuuF4rMD6"
      },
      "source": [
        "# Exercise 3 â€“ Independence-based Causal Structure Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p21N9AFBrB0o"
      },
      "source": [
        "__a)__\n",
        "\n",
        "Assume $P^{X,Y,Z}$ is Markov and faithful wrt. $G$. Assume all (!) conditional independences are\n",
        "\n",
        "$$\n",
        "\\newcommand{\\indep}{{\\,â««\\,}}\n",
        "\\newcommand{\\dep}{\\not{}\\!\\!\\indep}\n",
        "$$\n",
        "\n",
        "$$X \\indep Z \\mid \\emptyset$$\n",
        "\n",
        "(plus symmetric statements). What is $G$?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** This uniquely determines the graph as $X \\to Y \\leftarrow Z$."
      ],
      "metadata": {
        "id": "YTDNkX4QU_z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__b)__ (optional; this one is more tricky)\n",
        "\n",
        "Assume $P^{W,X,Y,Z}$ is Markov and faithful wrt. $G$. Assume all (!) conditional independences are\n",
        "\n",
        "$$\\begin{aligned}\n",
        "(Y,Z) &\\indep W \\mid \\emptyset \\\\\n",
        "W &\\indep Y \\mid (X,Z) \\\\\n",
        "(X,W) &\\indep Y | Z\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "(plus symmetric statements). What is $G$?"
      ],
      "metadata": {
        "id": "AIv5pu1OVBcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** The graphs with edges $\\{W,Z\\}\\to X$ and either (i) $Z\\to Y$ or (ii)  $Y\\to Z$.\n",
        "\n",
        "Note: you can check your answers using this free online tool: https://www.dagitty.net/dags.html#"
      ],
      "metadata": {
        "id": "ujClJDLsVCF4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "craCADN8rKd3"
      },
      "source": [
        "# Exercise 4 â€“ Additive Noise Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlFh1Zk50_z7"
      },
      "source": [
        "Set-up required packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk3IE7jvvUxG"
      },
      "outputs": [],
      "source": [
        "!mkdir ../data/\n",
        "!wget https://raw.githubusercontent.com/sweichwald/causality-tutorial-exercises/main/data/Exercise-ANM.csv -q -O ../data/Exercise-ANM.csv\n",
        "!wget https://raw.githubusercontent.com/sweichwald/causality-tutorial-exercises/main/python/kerpy/__init__.py -q -O kerpy.py\n",
        "!pip install pygam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNsEcFUJ1P4I"
      },
      "outputs": [],
      "source": [
        "from kerpy import hsic\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pygam import GAM, s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmh91goS1DCT"
      },
      "source": [
        "Let's load and plot some real data set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hwvlkYX1EPW"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('../data/Exercise-ANM.csv')\n",
        "\n",
        "plt.scatter(data[\"X\"].values, data[\"Y\"].values, s=2.);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uDnv5eD2pGd"
      },
      "source": [
        "__a)__\n",
        "\n",
        "Do you believed that $X \\to Y$ or that $X \\gets Y$? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4owvM1J_2rcM"
      },
      "source": [
        "**Answer:** $X \\to Y$ because of the independent noise assumption: in the other direction, the noise would have to switch from bimodal to unimodal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYdffpZN2uDc"
      },
      "source": [
        "$$\n",
        "\\newcommand{\\indep}{{\\,â««\\,}}\n",
        "\\newcommand{\\dep}{\\not{}\\!\\!\\indep}\n",
        "$$\n",
        "\n",
        "__b)__\n",
        "Let us now try to get a more statistical answer. We have heard that we cannot\n",
        "have  \n",
        "$$Y = f(X) + N_Y,\\ N_Y \\indep X$$\n",
        "and\n",
        "$$X = g(Y) + N_X,\\ N_X \\indep Y$$\n",
        "at the same time.\n",
        "\n",
        "Given a data set over $(X,Y)$,\n",
        "we now want to decide for one of the two models.\n",
        "\n",
        "Come up with a method to do so.\n",
        "\n",
        "Hints:\n",
        "* `GAM(s(0)).fit(A, B).deviance_residuals(A, B)` provides residuals when regressing $B$ on $A$.\n",
        "* `hsic(a, b)` can be used as an independence test (here, `a` and `b` are $n \\times 1$ numpy arrays)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llz5Eeck2xz5"
      },
      "outputs": [],
      "source": [
        "X = data[\"X\"].values\n",
        "Y = data[\"Y\"].values\n",
        "\n",
        "# fitting GAM both directions\n",
        "modelforw = GAM(s(0)).fit(X, Y)\n",
        "modelbackw = GAM(s(0)).fit(Y, X)\n",
        "\n",
        "# getting residuals for each model\n",
        "resforw = modelforw.deviance_residuals(X, Y)\n",
        "resbackw = modelbackw.deviance_residuals(Y, X)\n",
        "\n",
        "# independence tests\n",
        "pval_XY = hsic(resforw[:, np.newaxis], X[:, np.newaxis])\n",
        "pval_YX = hsic(resbackw[:, np.newaxis], Y[:, np.newaxis])\n",
        "\n",
        "print(\"p-values for rejecting the null hypothesis (independence of input and residuals)\")\n",
        "print(\"X->Y:\", pval_XY)\n",
        "print(\"Y->X:\", pval_YX)\n",
        "\n",
        "# creating plots\n",
        "fig, axes = plt.subplots(2, 1, figsize=(7, 10))\n",
        "\n",
        "axes[0].scatter(X, Y, s=2.)\n",
        "axes[0].scatter(X, modelforw.predict(X))\n",
        "axes[0].set_xlabel('X')\n",
        "axes[0].set_ylabel('Y')\n",
        "\n",
        "axes[1].scatter(Y,X, s=2.)\n",
        "axes[1].scatter(Y, modelbackw.predict(Y))\n",
        "axes[1].set_xlabel('Y')\n",
        "axes[1].set_ylabel('X')\n",
        "\n",
        "axes[0].set_title('X -> Y, pval: {:.4f}'.format(pval_XY))\n",
        "axes[1].set_title('Y -> X, pval: {:.4f}'.format(pval_YX))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8SBfEFi6oqH"
      },
      "source": [
        "__c)__\n",
        "\n",
        "Assume that the error terms are Gaussian with zero mean and variances\n",
        "$\\sigma_X^2$ and $\\sigma_Y^2$, respectively.\n",
        "The maximum likelihood for DAG G is\n",
        "then proportional to\n",
        "$-\\log(\\mathrm{var}(R^G_X)) - \\log(\\mathrm{var}(R^G_Y))$,\n",
        "where $R^G_X$ and $R^G_Y$ are the residuals obtained from regressing $X$ and $Y$ on\n",
        "their parents in $G$, respectively (no proof).\n",
        "\n",
        "Find the maximum likelihood solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pASFG1DC6sQA"
      },
      "outputs": [],
      "source": [
        "# computing scores proportional to the likelihoods\n",
        "print('X    Y: {:.2f}'.format(- np.log(np.var(X)) - np.log(np.var(Y)))) # X Y\n",
        "print('X -> Y: {:.2f}'.format(- np.log(np.var(X)) - np.log(np.var(resforw)))) # X -> Y\n",
        "print('Y -> X: {:.2f}'.format(- np.log(np.var(resbackw)) - np.log(np.var(Y)))) # X <- Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4JPYnSHrOfW"
      },
      "source": [
        "# Exercise 5 â€“ Invariant Causal Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb5CwEUEAaOp"
      },
      "source": [
        "Set-up required packages and data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wudBwtYswFeo"
      },
      "outputs": [],
      "source": [
        "!mkdir ../data/\n",
        "!wget https://raw.githubusercontent.com/sweichwald/causality-tutorial-exercises/main/data/Exercise-ICP.csv -q -O ../data/Exercise-ICP.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIosbymbbkhg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy8eUIaDdmrz"
      },
      "source": [
        "__a)__\n",
        "\n",
        "Generate some observational and interventional data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGBQGfetbYPj"
      },
      "outputs": [],
      "source": [
        "# Generate n=1000 observations from the observational distribution\n",
        "na = 1000\n",
        "Xa = np.random.normal(size=na)\n",
        "Ya = 1.5*Xa + np.random.normal(size=na)\n",
        "\n",
        "# Generate n=1000 observations from an interventional distribution\n",
        "nb = 1000\n",
        "Xb = np.random.normal(loc=2, scale=1, size=nb)\n",
        "Yb = 1.5*Xb + np.random.normal(size=nb)\n",
        "\n",
        "# plot Y vs X1\n",
        "fig, ax = plt.subplots(figsize=(7,5))\n",
        "ax.scatter(Xa, Ya, label='observational', marker='o', alpha=0.6)\n",
        "ax.scatter(Xb, Yb, label='interventional', marker ='^', alpha=0.6)\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZcSibWjypDR"
      },
      "source": [
        "Look at the above plot. Is the predictor $\\{X\\}$ an invariant set, that is (roughly speaking), does $Y \\mid X = x$ have the same distribution in the orange and blue data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhnmzEIiyvmt"
      },
      "source": [
        "**Answer:** Yes. Even though the marginal distribution of $X$ changes, the conditional distribution of $Y$ given $X=x$ appears to be the same for all $x$ across the two samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnDdgV_QeEFH"
      },
      "source": [
        "__b)__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqcN5gRdeRoi"
      },
      "source": [
        "We now consider data over a response and three covariates $X_1, X_2$, and $X_3$\n",
        "and try to infer $\\mathrm{pa}(Y)$. To do so, we need to find all sets for which this\n",
        "invariance is satisfied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4vMv59_wjKG"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "data = pd.read_csv('../data/Exercise-ICP.csv')\n",
        "data['env'] = np.concatenate([np.repeat('observational', 140), np.repeat('interventional', 80)])\n",
        "# pairplot\n",
        "sns.pairplot(data, hue='env', height=2, plot_kws={'alpha':0.6});"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yF7KhYZe7g9"
      },
      "outputs": [],
      "source": [
        "# The code below plots the residuals versus fitted values for all sets of\n",
        "# predictors.\n",
        "# extract response and predictors\n",
        "\n",
        "Y = data['Y'].to_numpy()\n",
        "X = data[['X1','X2','X3']].to_numpy()\n",
        "# get environment indicator\n",
        "obs_ind = data[data['env'] == 'observational'].index\n",
        "int_ind = data[data['env'] == 'interventional'].index\n",
        "# create all sets\n",
        "all_sets = [(0,), (1,), (2,), (0,1), (0,2), (1,2), (0,1,2)]\n",
        "# label each set\n",
        "set_labels = ['X1', 'X2', 'X3', 'X1,X2', 'X1,X3', 'X2,X3', 'X1,X2,X3']\n",
        "\n",
        "# fit OLS and store fitted values and residuals for each set\n",
        "fitted = []\n",
        "resid = []\n",
        "for s in all_sets:\n",
        "  model = sm.OLS(Y, X[:, s]).fit()\n",
        "  fitted += [model.fittedvalues]\n",
        "  resid += [model.resid]\n",
        "\n",
        "# plotting function\n",
        "def plot_fitted_resid(fv, res, ax, title):\n",
        "  ax.scatter(fv[obs_ind], res[obs_ind], label='observational', marker='o', alpha=0.6)\n",
        "  ax.scatter(fv[int_ind], res[int_ind], label='interventional', marker ='^', alpha=0.6)\n",
        "  ax.legend()\n",
        "  ax.set_xlabel('fitted values')\n",
        "  ax.set_ylabel('residuals')\n",
        "  ax.set_title(title)\n",
        "\n",
        "# creating plots\n",
        "fig, axes = plt.subplots(4, 2, figsize=(7,14))\n",
        "\n",
        "# plot result for the empty set predictor\n",
        "ax0 = axes[0,0]\n",
        "ax0.scatter(obs_ind, Y[obs_ind], label='observational', marker='o', alpha=0.6)\n",
        "ax0.scatter(int_ind, Y[int_ind], label='interventional', marker ='^', alpha=0.6)\n",
        "ax0.legend()\n",
        "ax0.set_xlabel('index')\n",
        "ax0.set_ylabel('Y')\n",
        "ax0.set_title('empty set')\n",
        "\n",
        "# plot result for the other sets\n",
        "for i, ax in enumerate(axes.flatten()[1:]):\n",
        "  plot_fitted_resid(fitted[i], resid[i], ax, set_labels[i])\n",
        "\n",
        "# make tight layout\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GfZKCL7zJve"
      },
      "source": [
        "Which of the sets are invariant? (There are two plots with four scatter plots each.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0sgjfRSzWEt"
      },
      "source": [
        "**Answer:** $\\{X_1, X_2, X_3\\}$ and $\\{X_1, X_2\\}$ since the distribution of residuals for these sets appears to be the same across all domains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO7tZSjLzMr0"
      },
      "source": [
        "__c)__\n",
        "What is your best guess for $\\mathrm{pa}(Y)$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6QtA9p9zdD7"
      },
      "source": [
        "**Answer:** The intersection of the two sets, that is, $\\{X_1, X_2\\}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZGGVS8lP0Ly"
      },
      "source": [
        "__d) (optional)__\n",
        "\n",
        "Use the function ICP to check your result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Qi2_GCnQmEG"
      },
      "outputs": [],
      "source": [
        "!pip install causalicp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqUzMXw5QLva"
      },
      "outputs": [],
      "source": [
        "import causalicp as icp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "raw = pd.read_csv('../data/Exercise-ICP.csv')\n",
        "data = [raw[:140], raw[140:]]\n",
        "icp.fit(data, 0, alpha=0.05, precompute=True, verbose=True, color=False)"
      ],
      "metadata": {
        "id": "bUBJrGQbmuJ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}